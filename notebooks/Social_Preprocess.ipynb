{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab4cf946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from typing import Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea5ad60",
   "metadata": {},
   "source": [
    "# 1단계 : 데이터 로딩 및 기본 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5572a",
   "metadata": {},
   "source": [
    "### 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74a878f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 234036 entries, 0 to 234035\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        234036 non-null  object\n",
      " 1   category  234036 non-null  object\n",
      " 2   date      234036 non-null  int64 \n",
      " 3   title     227043 non-null  object\n",
      " 4   content   231420 non-null  object\n",
      " 5   url       234036 non-null  object\n",
      " 6   source    234036 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 12.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# 소셜 데이터 전체 불러오기(234036)\n",
    "df = pd.read_csv('../data/raw/통합_소셜_데이터(원본 종합).csv', encoding='utf-8')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a22bd",
   "metadata": {},
   "source": [
    "### 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5851397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          변환 전  변환 후  증가분\n",
      "id           0     0    0\n",
      "category     0     0    0\n",
      "date         0     0    0\n",
      "title     6993  6997    4\n",
      "content   2616  2669   53\n",
      "url          0     0    0\n",
      "source       0     0    0\n"
     ]
    }
   ],
   "source": [
    "# 제목과 content에서 공백만 있는 경우 NaN으로 변환\n",
    "\n",
    "    # 변환 전 결측치\n",
    "before_missing = df.isnull().sum()\n",
    "\n",
    "    # 제목과 content에서 공백만 있는 경우 NaN으로 변환\n",
    "df['title'] = df['title'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "df['content'] = df['content'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    # 변환 후 결측치 개수 기록 \n",
    "after_missing = df.isnull().sum()\n",
    "\n",
    "    # 차이 계산\n",
    "diff_missing = after_missing - before_missing\n",
    "\n",
    "    # 보기 좋게 합치기\n",
    "missing_report = pd.DataFrame({\n",
    "    \"변환 전\": before_missing,\n",
    "    \"변환 후\": after_missing,\n",
    "    \"증가분\": diff_missing\n",
    "})\n",
    "print(missing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2031ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title이 비어있어서 content로 채운 개수: 6997\n",
      "content가 비어있어서 title로 채운 개수: 2669\n"
     ]
    }
   ],
   "source": [
    "# title,content 비어있을 경우 상호 채우기\n",
    "\n",
    "    # title이 비어있으면 content 값으로 채움\n",
    "title_fill_count = df['title'].isna().sum()\n",
    "df['title'] = df['title'].fillna(df['content'])\n",
    "\n",
    "    # content가 비어있으면 title 값으로 채움\n",
    "content_fill_count = df['content'].isna().sum()\n",
    "df['content'] = df['content'].fillna(df['title'])\n",
    "\n",
    "print(f\"title이 비어있어서 content로 채운 개수: {title_fill_count}\")\n",
    "print(f\"content가 비어있어서 title로 채운 개수: {content_fill_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911b6b1",
   "metadata": {},
   "source": [
    "### 텍스트 정제 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5926d7c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id        category            date  \\\n",
      "0  009992f3-67ce-4c9d-87f8-8b70add1dc5b  개인정보보호법,정보통신망법  20250813112502   \n",
      "1  7321a306-2153-41a8-8426-82ba3b2ac694  개인정보보호법,정보통신망법  20250813105737   \n",
      "2  29202426-c3bc-4e81-8146-b603869b0801  개인정보보호법,정보통신망법  20250813003504   \n",
      "3  b554082d-3d28-47e9-8b6a-5335e228ef0c  개인정보보호법,정보통신망법  20250812211635   \n",
      "4  aff109b1-f50d-4256-bd21-46ca16eaf097  개인정보보호법,정보통신망법  20250812174510   \n",
      "\n",
      "                                               title  \\\n",
      "0  우왁굳 왁물원 네이버 카페 api 무단 사용개인정보 수집 논란법 위반 소지 개인정보...   \n",
      "1  형사전문변호사가 말하는 명예훼손죄 성립요건 명예훼손죄는 형법 및 정보통신망법에 따라...   \n",
      "2  개인정보보호법 제 17조에 따르면 제 3자 즉 공연 주최 측에게 신분증 같은 걸 제...   \n",
      "3  빅데이터 및 인공지능 시대 정보주체 권리 보호 위한개인정보보호법 개정안발의 기자회견...   \n",
      "4  유튜브 등의 허위조작정보혐오폭력 선동 콘텐츠는 언론중재법방송법으로는 적용범위가 협소...   \n",
      "\n",
      "                                             content  \\\n",
      "0  우왁굳 왁물원 네이버 카페 api 무단 사용개인정보 수집 논란법 위반 소지 개인정보...   \n",
      "1  형사전문변호사가 말하는 명예훼손죄 성립요건 명예훼손죄는 형법 및 정보통신망법에 따라...   \n",
      "2  개인정보보호법 제 17조에 따르면 제 3자 즉 공연 주최 측에게 신분증 같은 걸 제...   \n",
      "3  빅데이터 및 인공지능 시대 정보주체 권리 보호 위한개인정보보호법 개정안발의 기자회견...   \n",
      "4  유튜브 등의 허위조작정보혐오폭력 선동 콘텐츠는 언론중재법방송법으로는 적용범위가 협소...   \n",
      "\n",
      "                                                 url   source  \n",
      "0  https://twitter.com/minsimnews/status/19554555...  twitter  \n",
      "1  https://twitter.com/internettellaw/status/1955...  twitter  \n",
      "2  https://twitter.com/dpcks_613/status/195529195...  twitter  \n",
      "3  https://twitter.com/jinbonet/status/1955242006...  twitter  \n",
      "4  https://twitter.com/choijinsoon/status/1955188...  twitter  \n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정제\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    content나 title 안에서 url, 특수문자, 이모티콘을 제거합니다.\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "\n",
    "    # 1. URL 제거\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', str(text))\n",
    "    \n",
    "    # 2. 이모티콘 제거\n",
    "    emoji_pattern = re.compile(\"[\"  \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text)\n",
    "    \n",
    "    # 3. 특수문자 제거 (한글, 영어, 숫자, 공백 제외)\n",
    "    text = re.sub(r'[^\\w\\s가-힣]', '', text)\n",
    "    \n",
    "    # 4. 여러 개의 공백을 하나로 축소\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # 5. 반복되는 자음, 모음 처리 (예: ㅋㅋㅋㅋ -> ㅋㅋ)\n",
    "    text = re.sub(r'([ㄱ-ㅎㅏ-ㅣ])\\1{2,}', r'\\1\\1', text)\n",
    "\n",
    "    # 6. 영문 소문자 변환\n",
    "    text = text.lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "# -------------------------\n",
    "# df에 정제 결과 반영\n",
    "# -------------------------\n",
    "# title과 content 둘 다 정제\n",
    "df['title'] = df['title'].astype(str).apply(clean_text)\n",
    "df['content'] = df['content'].astype(str).apply(clean_text)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6e90e",
   "metadata": {},
   "source": [
    "### 템플릿 정의 및 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a26b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- df['content']를 기반으로 블랙리스트 생성을 시작합니다. ---\n",
      "블랙리스트 생성 완료: 62개의 템플릿 문장을 찾았습니다.\n",
      "\n",
      "✅ 블랙리스트를 '../data/processed\\blacklistTempelte.txt' 파일로 성공적으로 저장했습니다.\n",
      "\n",
      "--- 생성된 블랙리스트를 적용하여 템플릿 문장 제거를 시작합니다. ---\n",
      "템플릿 문장 제거 완료.\n",
      "\n",
      "--- 템플릿 제거 후 content 열 (상위 5개) ---\n",
      "                                             content\n",
      "0  우왁굳 왁물원 네이버 카페 api 무단 사용개인정보 수집 논란법 위반 소지 개인정보...\n",
      "1  형사전문변호사가 말하는 명예훼손죄 성립요건 명예훼손죄는 형법 및 정보통신망법에 따라...\n",
      "2  개인정보보호법 제 17조에 따르면 제 3자 즉 공연 주최 측에게 신분증 같은 걸 제...\n",
      "3  빅데이터 및 인공지능 시대 정보주체 권리 보호 위한개인정보보호법 개정안발의 기자회견...\n",
      "4  유튜브 등의 허위조작정보혐오폭력 선동 콘텐츠는 언론중재법방송법으로는 적용범위가 협소...\n",
      "\n",
      "--- 생성된 블랙리스트 (상위 5개 샘플) ---\n",
      "1: 디지털성범죄 앞으로 저는 어떻게 될까요\n",
      "2: 출석 법무법인 에스 유튜브 법률상담은 카카오톡 채팅상담 클릭 강제추행 카메라촬영죄 아청법 아청물소지 n번방 성매매 지하철성추행 공중밀집장소추행 아동청소년강제추행 아청성매수 아동복지법 통매음 음란물유포 토렌트 준강간 압수수색 등\n",
      "3: 보이스피싱 때문에 경찰서에서 전화왔습니다\n",
      "4: 안녕하세요 요즘 제일 핫한 중대재해처벌법제조업 방문영업하실 분 모집합니다 단순 방문영업 입니다 중대재해처벌법인 안전보건경영시스템 구축을 갖추면 산재보험료를 20 매년 감면해줍니다 예를 들어 10인 사업장이 1년에 1000만원의 산재보험료를 낸다면 20인 200만원을 매년 감면해 줍니다 자동차보험의 블랙박스를 달면 보험료 7 감면해주는 것과 같은 이치입니다 수도권 및 충청도 방문영업 전화상담 관심 있으신분 문의 주세요 중대재해처벌법의 안전보건시스템구축을 정부에서 제조업에 한해 무상지원해 주고 있습니다 이에 관한 영업을 하시면 됩니다 전화 01028561058 이메일 주소 cleanplus3navercom\n",
      "5: 필독메모인증 안하면 무통보삭제\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 제거 함수 정의\n",
    "\n",
    "    # 1. 블랙리스트 생성을 위한 텍스트 정규화 함수\n",
    "def normalize_text_for_blacklist(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s가-힣]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip().lower()\n",
    "    return text\n",
    "\n",
    "    # 2. df['content']를 직접 받아 블랙리스트를 생성하고, Set으로 바로 반환하는 함수\n",
    "def create_blacklist_from_content(content_series: pd.Series, min_freq: int, min_len: int) -> Set[str]:\n",
    "    \"\"\"\n",
    "    DataFrame의 'content' Series를 직접 받아 템플릿 블랙리스트(Set)를 생성합니다.\n",
    "    \"\"\"\n",
    "    print(\"--- df['content']를 기반으로 블랙리스트 생성을 시작합니다. ---\")\n",
    "    \n",
    "    # 문장 분리\n",
    "    sentences = content_series.astype(str).str.replace(r'_x000d_', '\\n').str.split(r'[.\\n!?|;:]|ex\\s').explode()\n",
    "    # 문장 정규화\n",
    "    normalized_sentences = sentences.apply(normalize_text_for_blacklist)\n",
    "    # 길이 필터링\n",
    "    filtered_sentences = normalized_sentences[normalized_sentences.str.len() >= min_len]\n",
    "    # 빈도수 계산\n",
    "    sentence_counts = Counter(filtered_sentences)\n",
    "    # 블랙리스트 생성\n",
    "    blacklist_set = {sentence for sentence, count in sentence_counts.items() if count >= min_freq}\n",
    "    \n",
    "    print(f\"블랙리스트 생성 완료: {len(blacklist_set)}개의 템플릿 문장을 찾았습니다.\")\n",
    "    return blacklist_set\n",
    "\n",
    "    # 3. 생성된 블랙리스트를 적용하여 템플릿 문장을 제거하는 함수\n",
    "def remove_templates(original_text: str, blacklist: Set[str]) -> str:\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 블랙리스트에 포함된 문장을 제거합니다.\n",
    "    \"\"\"\n",
    "    if not isinstance(original_text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    raw_sentences = re.split(r'[.\\n!?|;:]|ex\\s', original_text)\n",
    "    clean_sentences = []\n",
    "    for s in raw_sentences:\n",
    "        normalized_s = normalize_text_for_blacklist(s)\n",
    "        if normalized_s and normalized_s not in blacklist:\n",
    "            clean_sentences.append(s.strip())\n",
    "            \n",
    "    return \" \".join(clean_sentences)\n",
    "\n",
    "\n",
    "\n",
    "# 템플릿 제거 실행\n",
    "\n",
    "# --- 설정값 ---\n",
    "MIN_FREQUENCY = 50  # 템플릿 문장 최소 빈도\n",
    "MIN_LENGTH = 15     # 템플릿 문장 최소 길이\n",
    "\n",
    "# 1. 위에서 전처리된 df['content']를 사용하여 바로 블랙리스트 생성\n",
    "blacklist_set = create_blacklist_from_content(\n",
    "    content_series=df['content'],\n",
    "    min_freq=MIN_FREQUENCY,\n",
    "    min_len=MIN_LENGTH\n",
    ")\n",
    "\n",
    "# 2. [추가] 생성된 블랙리스트를 txt 파일로 저장\n",
    "\n",
    "output_dir = \"../data/processed\"\n",
    "\n",
    "blacklist_filename = os.path.join(output_dir, \"blacklistTemplate.txt\")\n",
    "try:\n",
    "    with open(blacklist_filename, 'w', encoding='utf-8') as f:\n",
    "        # set은 순서가 없으므로, 정렬하여 저장하면 일관된 결과를 얻을 수 있습니다.\n",
    "        for sentence in sorted(list(blacklist_set)):\n",
    "            f.write(sentence + '\\n')\n",
    "    print(f\"\\n✅ 블랙리스트를 '{blacklist_filename}' 파일로 성공적으로 저장했습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❗️ 블랙리스트 파일 저장 중 오류가 발생했습니다: {e}\")\n",
    "\n",
    "\n",
    "# 3. 생성된 블랙리스트를 df['title'],df['content']에 바로 적용\n",
    "print(\"\\n--- 생성된 블랙리스트를 적용하여 템플릿 문장 제거를 시작합니다. ---\")\n",
    "df['title'] = df['title'].astype(str).apply(lambda x: remove_templates(x, blacklist_set))\n",
    "df['content'] = df['content'].astype(str).apply(lambda x: remove_templates(x, blacklist_set))\n",
    "\n",
    "print(\"템플릿 문장 제거 완료.\")\n",
    "\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n--- 템플릿 제거 후 content 열 (상위 5개) ---\")\n",
    "print(df[['content']].head())\n",
    "\n",
    "# 4. [추가] 생성된 블랙리스트의 상위 5개 샘플을 출력\n",
    "print(\"\\n--- 생성된 블랙리스트 (상위 5개 샘플) ---\")\n",
    "if blacklist_set:\n",
    "    # Set은 순서가 없으므로 list로 변환하여 일부를 확인합니다.\n",
    "    blacklist_sample = list(blacklist_set)[:5]\n",
    "    for i, sentence in enumerate(blacklist_sample):\n",
    "        print(f\"{i+1}: {sentence}\")\n",
    "else:\n",
    "    print(\"생성된 블랙리스트가 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806cd58",
   "metadata": {},
   "source": [
    "# 2단계: 데이터 제거 (중복 및 불필요 데이터) & 광고성 게시물 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36085e7",
   "metadata": {},
   "source": [
    "### 불필요 데이터 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56527bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 228803 entries, 0 to 234035\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        228803 non-null  object\n",
      " 1   category  228803 non-null  object\n",
      " 2   date      228803 non-null  int64 \n",
      " 3   title     228803 non-null  object\n",
      " 4   content   228803 non-null  object\n",
      " 5   url       228803 non-null  object\n",
      " 6   source    228803 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 14.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# 템플릿 제거 후 content가 NaN, 공백, 또는 'nan' 문자열인 경우 제거\n",
    "df = df[\n",
    "    ~(df['content'].isna()) &                                       # 1. NaN 값 제거\n",
    "    (df['content'].str.strip() != \"\") &                             # 2. 공백만 있는 경우 제거\n",
    "    (df['content'].str.strip().str.lower() != 'nan')                # 3. 'nan' 문자열(대소문자 무관) 제거\n",
    "]\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c6358",
   "metadata": {},
   "source": [
    "### 완전 빈 데이터 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f7b3d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 211261 entries, 163672 to 164761\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   id        211261 non-null  object\n",
      " 1   category  211261 non-null  object\n",
      " 2   date      211261 non-null  int64 \n",
      " 3   title     211261 non-null  object\n",
      " 4   content   211261 non-null  object\n",
      " 5   url       211261 non-null  object\n",
      " 6   source    211261 non-null  object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 12.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# title과 content가 완전히 일치하는 데이터 중에서, date가 가장 빠른 행만 남기고 나머지 제거\n",
    "df = df.sort_values('date').drop_duplicates(subset=['title', 'content'], keep='first')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2e143",
   "metadata": {},
   "source": [
    "### 광고성 게시물 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "427d2e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- '강한 신호' 기반 광고 필터링 시작 ---\n",
      "필터링 시작 전 데이터 개수: 211261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "광고 필터링 진행중: 100%|██████████| 211261/211261 [02:47<00:00, 1262.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "광고 제거 후 남은 데이터: 146598\n",
      "광고로 제거된 데이터: 64663\n"
     ]
    }
   ],
   "source": [
    "# 정규식 처리\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas(desc=\"광고 필터링 진행중\")\n",
    "print(\"--- '강한 신호' 기반 광고 필터링 시작 ---\")\n",
    "\n",
    "# 전처리 된 df로 처리\n",
    "original_count = len(df)\n",
    "print(f\"필터링 시작 전 데이터 개수: {original_count}\")\n",
    "\n",
    "# =========================\n",
    "# 광고 패턴 및 유형 정의\n",
    "# =========================\n",
    "STRONG_PATTERNS = [\n",
    "    # (A) 협찬/광고 고지/해시태그\n",
    "    r\"(원고료\\s*를\\s*받[아았]|협찬\\s*받[아았]|광고\\s*표기|#?\\s?(광고|협찬)|\\bAD\\b|\\bPR\\b)\",\n",
    "    # (B) 직접 행동 유도 CTA / 구매/예약\n",
    "    r\"(바로가기|자세히\\s*보기|상세\\s*보기|링크\\s*클릭|구매\\s*하기|신청\\s*하기|예약\\s*하기|구독\\s*하기)\",\n",
    "    # (C) 확실한 광고/유입 목적 URL만 필터링\n",
    "    r\"(smartstore\\.naver\\.com|linktr\\.ee|forms\\.gle|bit\\.ly|me2\\.do|t\\.co|shorturl\\.at|url\\.kr|tinyurl\\.com|bitly\\.com|naver\\.me)\",\n",
    "    # (D) 커머스 핵심 행위/혜택\n",
    "    r\"(장바구니|결제\\s*하기|무이자|할부|무료\\s*배송|교환|환불)\",\n",
    "    # (E) 할인/특가/가격(명시적 판매)\n",
    "    r\"(\\b\\d{1,3}\\s?%(\\s*할인)?|할인\\s*\\d{1,2}\\s*%|할인\\s*행사|특가\\s*행사)\",\n",
    "    r\"((판매가|할인가|행사가|정가)\\s*[\\d,]+(?:원|원\\s*입니다)|\\b[\\d,]+원\\s*(에\\s*판매|구매))\",\n",
    "    # (F) 연락처/대표번호\n",
    "    r\"([0-9]{2,3}-[0-9]{3,4}-[0-9]{4})\",\n",
    "    r\"\\b01[016789][\\s\\.-]?\\d{3,4}[\\s\\.-]?\\d{4}\\b\",\n",
    "    r\"(\\+82[-\\s]?(?:10|1[6-9]|2|[3-6][1-5])[-\\s]?\\d{3,4}[-\\s]?\\d{4})\",\n",
    "    r\"(대표번호|대표전화|고객센터|ARS)\\s*\\d{2,4}[-]?\\d{3,4}[-]?\\d{3,4}\",\n",
    "    # (G) 메신저/채널 유도\n",
    "    r\"(open\\.kakao\\.com|카카오톡\\s*채널|카카오\\s*채널|오픈채팅|카톡\\s*오픈|텔레그램|Telegram|라인\\s*ID|카카오\\s*ID|카톡\\s*ID|네이버\\s*톡톡|톡톡|플러스친구|플친)\",\n",
    "    # (H) 부동산 실판매 문의/예약\n",
    "    r\"(분양\\s*문의|청약\\s*문의|상담전화|상담\\s*예약|모델하우스\\s*방문\\s*예약|견본주택\\s*방문)\",\n",
    "    # (I) 희소성/마감 압박\n",
    "    r\"(선착순|마감\\s*(임박|주의)|한정\\s*(수량|판매)|오늘\\s*마감|지금\\s*신청)\",\n",
    "    # (J) 교육 영업\n",
    "    r\"(수강생\\s*모집|원서\\s*접수|합격\\s*보장|설명회\\s*신청)\",\n",
    "    # (K) 플랫폼/라이브커머스/선물하기\n",
    "    r\"(쿠팡|coupang|스마트스토어|스토어찜|오늘의딜|쇼핑라이브|라이브\\s*커머스|라방|선물하기|카카오\\s*선물|톡딜|네이버페이|카카오페이|토스|페이코)\",\n",
    "    # (L) B2B 영업/계좌 안내\n",
    "    r\"(단체\\s*주문|대량\\s*주문|견적\\s*요청|납품|B2B|총판|대리점|입점문의|제휴\\s*문의)\",\n",
    "    r\"(계좌|입금|입금자명|송금|무통장\\s*입금)\\s*[^\\n]{0,12}\\d{2,4}[- ]?\\d{3,4}[- ]?\\d{3,4}\",\n",
    "    # (M) 사전예약/런칭\n",
    "    r\"(오픈\\s*기념|얼리버드|사전\\s*(구매|등록|신청))\",\n",
    "    # (N) SNS 참여형 이벤트\n",
    "    r\"(댓글\\s*이벤트|팔로우\\s*이벤트|공유\\s*이벤트|리그램|추첨|당첨|경품)\",\n",
    "]\n",
    "\n",
    "strong_rgx = re.compile(\"|\".join(STRONG_PATTERNS), re.IGNORECASE)\n",
    "\n",
    "# 1) 광고 필터\n",
    "is_ad_mask = df['content'].astype(str).progress_apply(lambda x: bool(strong_rgx.search(x)))\n",
    "df_ad_cleaned   = df[~is_ad_mask].copy()  # 광고가 아닌 데이터\n",
    "df_ads_removed  = df[ is_ad_mask].copy()  # 광고로 제거된 데이터\n",
    "\n",
    "print(f\"광고 제거 후 남은 데이터: {len(df_ad_cleaned)}\")\n",
    "print(f\"광고로 제거된 데이터: {len(df_ads_removed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bca7c1",
   "metadata": {},
   "source": [
    "# 3단계: 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "218799d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "저장 완료!\n",
      "- 광고 제거 데이터(CSV): '../data/processed\\소셜_데이터_전처리완료.csv'\n",
      "- 제거된 광고 데이터(CSV): '../data/processed\\제거된_광고_데이터.csv'\n"
     ]
    }
   ],
   "source": [
    "# --- 결과 저장 (csv) ---\n",
    "\n",
    "output_dir = \"../data/processed\"\n",
    "\n",
    "out_cleaned_csv = os.path.join(output_dir, f\"소셜_데이터_전처리완료.csv\")\n",
    "out_removed_csv = os.path.join(output_dir, f\"제거된_광고_데이터.csv\")\n",
    "\n",
    "# CSV 저장\n",
    "df_ad_cleaned.to_csv(out_cleaned_csv, index=False, encoding=\"utf-8-sig\")\n",
    "df_ads_removed.to_csv(out_removed_csv, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"\\n저장 완료!\")\n",
    "\n",
    "print(f\"- 광고 제거 데이터(CSV): '{out_cleaned_csv}'\")\n",
    "print(f\"- 제거된 광고 데이터(CSV): '{out_removed_csv}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
